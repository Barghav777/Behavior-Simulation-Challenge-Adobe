{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 9785879,
          "sourceType": "datasetVersion",
          "datasetId": 5995788
        },
        {
          "sourceId": 9786304,
          "sourceType": "datasetVersion",
          "datasetId": 5996110
        }
      ],
      "dockerImageVersionId": 30787,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "accelerator": "TPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ATOGwgXaI_W",
        "outputId": "1d543431-2e98-4711-e30d-91c47712741f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPool1D, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "import time\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-02T10:02:28.339663Z",
          "iopub.execute_input": "2024-11-02T10:02:28.340588Z",
          "iopub.status.idle": "2024-11-02T10:02:40.327404Z",
          "shell.execute_reply.started": "2024-11-02T10:02:28.340546Z",
          "shell.execute_reply": "2024-11-02T10:02:40.326346Z"
        },
        "id": "YJoihXZCZ96H"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openpyxl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J06UbY-daaGC",
        "outputId": "819d3203-48a1-4a70-823d-383a4048472a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openpyxl\n",
            "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting et-xmlfile (from openpyxl)\n",
            "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.9/250.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: et-xmlfile, openpyxl\n",
            "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(\"/content/drive/MyDrive/colab/behaviour_simulation_train.xlsx\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-02T10:02:49.901611Z",
          "iopub.execute_input": "2024-11-02T10:02:49.902333Z",
          "iopub.status.idle": "2024-11-02T10:02:53.285056Z",
          "shell.execute_reply.started": "2024-11-02T10:02:49.902294Z",
          "shell.execute_reply": "2024-11-02T10:02:53.283973Z"
        },
        "id": "WyoV2fYJZ96I"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tweet = []\n",
        "for i in range(300000):\n",
        "    tweet.append(df['content'][i] + \" \" + df['date'][i] + \" \" + df['username'][i] + \" \" + df['inferred company'][i])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-02T10:02:53.286949Z",
          "iopub.execute_input": "2024-11-02T10:02:53.287287Z",
          "iopub.status.idle": "2024-11-02T10:02:53.299610Z",
          "shell.execute_reply.started": "2024-11-02T10:02:53.287253Z",
          "shell.execute_reply": "2024-11-02T10:02:53.298580Z"
        },
        "id": "JrfMZPHqZ96I"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df['tweet'] = tweet"
      ],
      "metadata": {
        "id": "Upg4yH1a34DE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['likes'] = pd.to_numeric(df['likes'], errors='coerce')\n",
        "df = df.dropna(subset=['likes'])\n",
        "\n",
        "df['likes'] = df['likes'].astype(int)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-02T10:02:53.300761Z",
          "iopub.execute_input": "2024-11-02T10:02:53.301082Z",
          "iopub.status.idle": "2024-11-02T10:02:53.446661Z",
          "shell.execute_reply.started": "2024-11-02T10:02:53.301049Z",
          "shell.execute_reply": "2024-11-02T10:02:53.445590Z"
        },
        "id": "CcsN2CCfZ96I"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df['tweet'] = df['tweet'].astype(str)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-02T10:03:09.130869Z",
          "iopub.execute_input": "2024-11-02T10:03:09.131618Z",
          "iopub.status.idle": "2024-11-02T10:03:09.154218Z",
          "shell.execute_reply.started": "2024-11-02T10:03:09.131576Z",
          "shell.execute_reply": "2024-11-02T10:03:09.153230Z"
        },
        "id": "WB01pJ0TZ96I"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False)\n",
        "bertweet = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "bertweet.to(device)\n",
        "bertweet.eval()\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "def get_bertweet_embeddings(sentences, model, tokenizer, device):\n",
        "    inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n",
        "\n",
        "    print(\"Input tensor shape:\", inputs[\"input_ids\"].shape)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
        "\n",
        "start = time.time()\n",
        "print(\"train data embeddings started\")\n",
        "\n",
        "X_test = None\n",
        "\n",
        "for start_idx in range(0, len(df), batch_size):\n",
        "    end_idx = min(start_idx + batch_size, len(df))\n",
        "    batch_sentences = [text for text in df[\"tweet\"].iloc[start_idx:end_idx].tolist() if text]\n",
        "\n",
        "    try:\n",
        "        X_batch = get_bertweet_embeddings(batch_sentences, bertweet, tokenizer, device)\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Error processing batch {start_idx} to {end_idx}: {e}\")\n",
        "        continue\n",
        "\n",
        "    if start_idx == 0:\n",
        "        X_test = X_batch\n",
        "    else:\n",
        "        X_test = np.concatenate([X_test, X_batch])\n",
        "\n",
        "np.save(\"content-test-company-full.npy\", X_test)\n",
        "\n",
        "print(f\"Time required = {time.time() - start}\")\n",
        "print(\"test data embeddings ended\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-02T10:03:10.784958Z",
          "iopub.execute_input": "2024-11-02T10:03:10.785712Z",
          "iopub.status.idle": "2024-11-02T10:03:10.791123Z",
          "shell.execute_reply.started": "2024-11-02T10:03:10.785672Z",
          "shell.execute_reply": "2024-11-02T10:03:10.790126Z"
        },
        "id": "zKC9IpLuZ96I"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "nvsnOidYZ96Q"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}